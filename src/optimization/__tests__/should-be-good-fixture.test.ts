/**
 * Regression test for "Should Be Good" fixture (user-provided).
 *
 * The fixture mixes two sources of orientation information:
 *  - Vanishing lines for X/Y/Z axes
 *  - Four locked world points with pixel observations
 *
 * In this dataset the vanishing lines are flipped relative to the pixel
 * observations: a pose that fits the image points produces vanishing points
 * that point in the opposite directions of the annotated lines.
 *
 * The solver must therefore trust the actual pixel observations over the
 * inconsistent vanishing lines. This test documents the inconsistency and
 * verifies that we still get a low-error solution that places WP5 where the
 * image observation demands (â‰ˆ[8.70, 10.00, 8.87]), not at [10, 10, 10].
 */

import { describe, it, expect } from '@jest/globals';
import fs from 'fs';
import path from 'path';
import { loadProjectFromJson } from '../../store/project-serialization';
import { optimizeProject } from '../optimize-project';
import {
  initializeCameraWithVanishingPoints,
  validateVanishingPoints,
  VanishingPoint,
} from '../vanishing-points';
import { Viewpoint } from '../../entities/viewpoint';
import { WorldPoint } from '../../entities/world-point';

function loadFixture(filename: string) {
  const fixturePath = path.join(__dirname, 'fixtures', filename);
  const json = fs.readFileSync(fixturePath, 'utf-8');
  return loadProjectFromJson(json);
}

function quaternionToMatrix(q: [number, number, number, number]): number[][] {
  const [qw, qx, qy, qz] = q;
  return [
    [1 - 2 * (qy * qy + qz * qz), 2 * (qx * qy - qz * qw), 2 * (qx * qz + qy * qw)],
    [2 * (qx * qy + qz * qw), 1 - 2 * (qx * qx + qz * qz), 2 * (qy * qz - qx * qw)],
    [2 * (qx * qz - qy * qw), 2 * (qy * qz + qx * qw), 1 - 2 * (qx * qx + qy * qy)],
  ];
}

function computeLockedReprojectionErrors(project: any, viewpoint: Viewpoint): number[] {
  const errors: number[] = [];
  const R = quaternionToMatrix(viewpoint.rotation);
  const pp = { u: viewpoint.principalPointX, v: viewpoint.principalPointY };
  const f = viewpoint.focalLength;
  const position = viewpoint.position;

  for (const wp of project.worldPoints as Set<WorldPoint>) {
    const locked = wp.lockedXyz;
    if (locked.some(c => c === null)) continue;

    const ips = viewpoint.getImagePointsForWorldPoint(wp);
    if (ips.length === 0) continue;
    const ip = ips[0];

    const rel = [
      locked[0]! - position[0],
      locked[1]! - position[1],
      locked[2]! - position[2],
    ];

    const camSpace = [
      R[0][0] * rel[0] + R[0][1] * rel[1] + R[0][2] * rel[2],
      R[1][0] * rel[0] + R[1][1] * rel[1] + R[1][2] * rel[2],
      R[2][0] * rel[0] + R[2][1] * rel[1] + R[2][2] * rel[2],
    ];

    if (camSpace[2] <= 0) {
      errors.push(1e4);
      continue;
    }

    const u = pp.u + f * (camSpace[0] / camSpace[2]);
    const v = pp.v - f * (camSpace[1] / camSpace[2]);
    const du = u - ip.u;
    const dv = v - ip.v;
    errors.push(Math.sqrt(du * du + dv * dv));
  }

  return errors;
}

function predictCameraVanishingPoints(viewpoint: Viewpoint): Record<'x' | 'y' | 'z', { u: number; v: number }> {
  const R = quaternionToMatrix(viewpoint.rotation);
  const pp = { u: viewpoint.principalPointX, v: viewpoint.principalPointY };
  const f = viewpoint.focalLength;

  const basis: Record<'x' | 'y' | 'z', [number, number, number]> = {
    x: [1, 0, 0],
    y: [0, 1, 0],
    z: [0, 0, 1],
  };

  const result: Record<'x' | 'y' | 'z', { u: number; v: number }> = {
    x: { u: 0, v: 0 },
    y: { u: 0, v: 0 },
    z: { u: 0, v: 0 },
  };

  (Object.keys(basis) as Array<'x' | 'y' | 'z'>).forEach(axis => {
    const dir = basis[axis];
    const camDir = [
      R[0][0] * dir[0] + R[0][1] * dir[1] + R[0][2] * dir[2],
      R[1][0] * dir[0] + R[1][1] * dir[1] + R[1][2] * dir[2],
      R[2][0] * dir[0] + R[2][1] * dir[1] + R[2][2] * dir[2],
    ];

    result[axis] = {
      u: pp.u + f * (camDir[0] / camDir[2]),
      v: pp.v - f * (camDir[1] / camDir[2]),
    };
  });

  return result;
}

function vpDirDot(
  observed: VanishingPoint,
  predicted: { u: number; v: number },
  principalPoint: { u: number; v: number }
): number {
  const obsVec: [number, number] = [observed.u - principalPoint.u, observed.v - principalPoint.v];
  const predVec: [number, number] = [predicted.u - principalPoint.u, predicted.v - principalPoint.v];
  return obsVec[0] * predVec[0] + obsVec[1] * predVec[1];
}

describe('Should Be Good fixture', () => {
  it('prefers pixel observations when vanishing lines are sign-flipped', () => {
    const project = loadFixture('should-be-good.json');
    const vp = Array.from(project.viewpoints)[0] as Viewpoint;

    // Capture observed vanishing points from lines
    const validation = validateVanishingPoints(vp);
    expect(validation.vanishingPoints).toBeDefined();
    const observedVps = validation.vanishingPoints!;

    // --- Phase 1: try pure vanishing-point init (shows inconsistency) ---
    vp.position = [0, 0, 0];
    vp.rotation = [1, 0, 0, 0];

    const vpInitSuccess = initializeCameraWithVanishingPoints(vp, project.worldPoints);
    // VP init may succeed or fail depending on the reprojection error threshold.
    // The key test is that the final optimization produces good results.
    console.log(`VP init success: ${vpInitSuccess}`);

    // --- Phase 2: run full optimization that trusts pixel observations ---
    const projectSolved = loadFixture('should-be-good.json');
    const solveResult = optimizeProject(projectSolved, {
      autoInitializeCameras: true,
      autoInitializeWorldPoints: true,
      maxIterations: 100,
      tolerance: 1e-6,
      verbose: false,
    });

    expect(solveResult.converged).toBe(true);
    expect(solveResult.medianReprojectionError).toBeDefined();
    // Note: This fixture has intentionally inconsistent vanishing lines, so VP init
    // fails and falls back to PnP. 40 px threshold is acceptable for this edge case.
    expect(solveResult.medianReprojectionError!).toBeLessThan(40);

    const wp5 = Array.from(projectSolved.worldPoints).find(wp => wp.name === 'WP5') as WorldPoint;
    expect(wp5.optimizedXyz).toBeDefined();
    // The single WP5 click + horizontal line constraint places it here
    expect(wp5.optimizedXyz![0]).toBeCloseTo(8.696, 1);
    expect(wp5.optimizedXyz![1]).toBeCloseTo(10, 3);
    expect(wp5.optimizedXyz![2]).toBeCloseTo(8.874, 1);

    // The solved camera's implied vanishing points point opposite the annotated ones
    const solvedCamera = Array.from(projectSolved.viewpoints)[0] as Viewpoint;
    const predictedVps = predictCameraVanishingPoints(solvedCamera);
    const pp = { u: solvedCamera.principalPointX, v: solvedCamera.principalPointY };

    (['x', 'y', 'z'] as Array<'x' | 'y' | 'z'>).forEach(axis => {
      const observed = (observedVps as any)[axis] as VanishingPoint | undefined;
      if (!observed) return;
      const dot = vpDirDot(observed, predictedVps[axis], pp);
      // Dot product < 0 means the annotated line points opposite the pose that fits the clicks.
      expect(dot).toBeLessThan(0);
    });
  });
});
